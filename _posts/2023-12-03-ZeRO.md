---
layout: post
title: ZeRO-Memory Optimizations Toward Training Trillion Parameter Models
subtitle: ZeRO family[1]
tags: [MLSys, Parallelism]
categories: [Parallel Training, Paper]
comments: true
author: SeaMount
---

随着深度神经网络模型的加深，模型的准确性也得到了相应的提升，但由于硬件条件的限制，在单个设备上训练数十亿至数万亿参数十分困难。当前通常会使用数据并行和模型并行的方法来解决训练大型模型显存首先的问题，但数据并行和模型并行均存在不足之处。数据并行虽然不需要进行频繁的通信，但是需要在每个处理器上复制一份完整的模型状态，造成模型的冗余；而模型并行虽然对模型状态进行了划分，能够减少模型状态冗余，更高效地使用内存，但是会导致计算粒度过细，需要频繁进行通信。

微软提出了 ZeRO，零冗余优化器来消除了模型并行和数据并行训练中的内存冗余，同时也保持了低通信量和高计算粒度。

本文认为，模型训练的过程中，内存消耗主要分为两个部分：
1. 模型状态，包括优化器状态（optimizer state）、梯度和参数，其中，优化器状态包括动量（momentum）和冲量（variance）；
2. 剩余状态，包括中间激活值（activations）、临时缓冲区和不可用的显存碎片。

本文分别针对以上两个消耗内存的主要部分提出了两种不同的方法，ZeRO-DP 和 ZeRO-R。

## 优化模型状态（model states）

ZeRO-DP 将模型状态进行切分，使每个处理器只保留模型状态的一部分，减少模型的冗余存储。提出了三个优化的阶段：
1. 优化器状态（optimizer states）

    在每个 GPU 中保存全部的参数和梯度，但是只保存 
    $$\frac{1}{N_d}$$
    的优化器状态变量。实验表明，切分优化器状态使内存占用减少 4 倍，与 DP 具有相同的通信量；
2. 梯度 + 优化器状态（gradients + optimizer states）

    每个gpu中只保存
    $$\frac{1}{N_d}$$
    的梯度，实验表明，切分梯度和优化器状态使内存占用减少 8 倍，与 DP 具有相同的通信量；
3. 参数 + 梯度 + 优化器状态（parameters + gradients + optimizer states）

    每个gpu中只保存
    $$\frac{1}{N_d}$$
    的参数 ，实验表明，切分参数、梯度和优化器状态能使内存占用减少 64 倍（内存减少量与 DP 划分的份数呈线性关系），通信量仅增加 50%。

![zero-partition](/assets/img/20231203/zero-partition.png)

{: .box-note}
Baseline: 未进行优化的基线 \
$$\Psi$$: 模型大小（参数的数量），途中模型大小为 7.5B \
K: 存储优化器状态要消耗的内存倍数，对于混合精度的 Adam 优化器而言，K = 12 \
$$N_d$$: 数据并行度。基于 Adam 优化器的混合精度训练，数据并行度为 $$N_d = 64$$，即在 64 块 GPU 上进行训练。

## 优化剩余状态（residual states）

ZeRO-R 针对中间激活值（activations）、临时缓冲区（buffer）和不可用的显存碎片占用，提出了以下优化点：

1. 使用针对激活值的检查点（checkpoint）来节省内存，同时还对激活值进行切片，根据需要将激活值数据卸载到 CPU 来减少激活值（activations）的显存占用；
2. 定义了适当的临时缓冲区大小，使内存和计算效率平衡；
3. 根据不同张量（tensor）的生命周期，主动管理内存，减少内存碎片产生的概率；

ZeRO-DP 和 ZeRO-R 结合起来被称为 ZeRO，零冗余优化器，既解决了数据并行中内存效率低下的问题，又解决了模型并行中计算和通信效率低下的问题。

